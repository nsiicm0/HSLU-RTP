---
title: "Exercise 4"
author: Niclas Simmler
date: 13.03.20
output: html_notebook
---

# Exercise 4.1
In this exercise, we would like to investigate the properties of an AR(1) process.

## a)
Simulate a realisation of the process Xt = 0.8X_t-1 + e_t with et an innovation process of length 1000.

```{r}
sim.data <- arima.sim(list(ar=c(0.8)), n=1000)
```

## b)
Calculate the theoretical autocorrelation function and the plug-in estimator of the autocorrelation of the simulation results in a) and plot both curves for lags from 0 to 100.

```{r}
theoretical.acf <- ARMAacf(ar=c(0.8), lag.max=100)
estimated.acf <- acf(sim.data, lag.max=100)
segments(0:100 + 0.1, 0, 0:100 + 0.1, theoretical.acf, col = "red")
```
## c)
What is the functional dependence of the theoretical autocorrelation function on the lag k and α1 = 0.8?

-

## d)
Now compare the theoretical partical autocorrelation function with the estima- ted version for the simulated process. Which particularity do you observe for the two representations?

```{r}
theoretical.pacf <- ARMAacf(ar=c(0.8), lag.max=100, pacf=TRUE)
estimated.pacf <- pacf(sim.data, lag = 100)
segments(1:100 + 0.1, 0, 1:100 + 0.1, theoretical.pacf, col = "red")
```
The PACF plot holds no information for data earlier than on lag = 1 (as expected). The estimated function holds interestingly enough some information for certain lags (exceeding confidence interval threshold).

# Exercise 4.2
An analytical device measures the creatine concentration of human muscular tissue. In this exercise, we would like to check whether it is operating correctly, i.e. the measured values does not depend on the measuring instance. A sample with known concentration is split into 157 samples and measured by the device one after the other. You can find them in the data under http://stat.ethz.ch/Teaching/Datasets/WBL/kreatin.dat . In this exercise, we focus only on the variable "gehalt" (content) in the data.

```{r}
library(forecast)
creatine <- read.table('http://stat.ethz.ch/Teaching/Datasets/WBL/kreatin.dat', header=TRUE)$gehalt
```

## a)
Which stochastic model should this series of data follow if the machine is working correctly?

We expected the machine to always measure the same result for the same object plus a time dependent error. So there should be no time dependent changes in the measurement in general.

## b)
Use the time series plot, the autocorrelations (and the partial autocorrelations) to determine whether these data fit the ideal model found in Part a) or not.

```{r}
creatine.ts <- ts(creatine, start=1, frequency=1)
tsdisplay(creatine.ts, points = FALSE)
```
The (P)ACF plots show dependencies in the lags. That means, that our thought after model does not apply here. In other words, no measurement is independent.



# Exercise 4.3
In this exercise, we consider two time series ts1 and ts2, which putatively were created by an AR process. You may download the data from
http://stat.ethz.ch/Teaching/Datasets/WBL/ts_S3_A2.dat

```{r}
ts1_ts2 <- read.table('http://stat.ethz.ch/Teaching/Datasets/WBL/ts_S3_A2.dat', header = TRUE)
```

## a)
Visualise both time series. Are both time series stationary? What is their mean?

```{r}
ts1 <- ts(ts1_ts2$ts1)
ts2 <- ts(ts1_ts2$ts2)
dat <- ts.union(TS1=ts1, TS2=ts2)
plot(dat, main = '')
mean(ts1)
sd(ts1)
mean(ts2)
sd(ts2)
```
TS1 seems to be a stationary timeseries with a mean of 6.97.
TS2 does seem to exhibit some sort of trend, although it being quite weak. The mean is at 0.3.

## b)
Consider the (partial) autocorrelation function and decide whether the two ti- me series can be generated by an AR process. If yes, what is the order of the respective AR process?
```{r}
par(mfrow=c(1,2))
acf(ts1)
pacf(ts1)
acf(ts2)
pacf(ts2)
```
TS1 exhibits significant deviations from 0 in lag 1 and 2 within the PACF plot. This would indicate a modelled AR(2) process. However, there is also the 7th lag exhibiting a significant deviation from 0. If the residuals still show dependencies in the AR(2) process, AR(7) shall be chosen.
TS2 exhibits significant deviations from 0 in lag 1, 2, 3 and 4 within the PACF plot. This indicates a modelled AR(4) process.

# Exercise 4.4

Let us consider the AR(3) model with coefficients α1 = 0.6, α2 = −0.5 and α3 = 0.4:
Xt =0.6·Xt−1−0.5·Xt−2+0.4·Xt−3

## a)
Simulate one realisation of length 50 of the time series and plot it. Would you assume that this time series is stationary?

```{r}
coeffs <- c(0.6, -0.5, 0.4)
sim.data <- arima.sim(list(ar=coeffs), n=50)
plot(sim.data)
```
I would not assume this time series to be stationary, but as it looks, the process seems to be stationary.

## b)
Calculate the estimated (partial) autocorrelation function and compare it to the theoretical function. Hint: Compare exercise 3.3 for hints.
```{r}
ACFt <- ARMAacf(coeffs, lag = 100)
PACFt <- ARMAacf(coeffs, pacf = TRUE, lag = 100)

par(mfrow=c(1,2))
ACFe <- acf(sim.data, lag = 100, ylim = c(-1, 1))
segments(0:100.1, 0, 0:100 + 0.1, ACFt, col = "red")
PACFe <- pacf(sim.data, lag = 100, ylim = c(-1, 1))
segments(0:100, 0, 0:100 + 0.1, PACFt, col = "red")
```
# c)
Preview to week 5: Calculate the roots of the polynomial Φ(z) = 1 − α1 · z − α2 · z2 − α3 · z3 with the R function polyroot. What do you observe for the absolute value of the roots?

```{r}
abs(polyroot(c(1,-coeffs)))
```
2 of the roots from the coefficients are identical.